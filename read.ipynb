{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyxdf\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "from autoreject import AutoReject\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_modalities_optimized(marker_timestamps, modality_timestamps, modality_data):\n",
    "    \"\"\"\n",
    "    Optimized segmentation of data for a modality based on marker timestamps, accommodating different sampling rates.\n",
    "\n",
    "    :param marker_timestamps: Timestamps of markers.\n",
    "    :param modality_timestamps: Timestamps of the modality data.\n",
    "    :param modality_data: Data of the modality to be segmented.\n",
    "    :return: A list of data segments for the modality.\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays for efficient computation\n",
    "    marker_timestamps = np.array(marker_timestamps)\n",
    "    modality_timestamps = np.array(modality_timestamps)\n",
    "\n",
    "    # Find insertion points for each marker in the modality timestamps\n",
    "    insert_points = np.searchsorted(modality_timestamps, marker_timestamps)\n",
    "    segments = []\n",
    "    for i in range(len(insert_points) - 1):\n",
    "        # Extract and store the segment\n",
    "        start_index = insert_points[i]\n",
    "        end_index = insert_points[i + 1]\n",
    "        segment = modality_data[start_index:end_index]\n",
    "        segments.append(segment)\n",
    "\n",
    "    # Handle the last segment, from the last marker to the end of the data stream\n",
    "    if insert_points[-1] < len(modality_data):\n",
    "        last_segment = modality_data[insert_points[-1]:]\n",
    "        segments.append(last_segment)\n",
    "    else:\n",
    "        # If the last marker is exactly at or beyond the end of the data, append an empty segment\n",
    "        segments.append([])\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, header = pyxdf.load_xdf('/Users/anarghya/Developer/eeg_data/multimodal-speech-eeg/dku/sub-8/part-1/sub-08_task-words_run-001.xdf',\n",
    "                              select_streams=[{'type': 'EEG'}, {'type': 'Markers'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = ['EEG', 'Markers', 'Audio']\n",
    "assert len(data) == 3\n",
    "# check whether the data has 3 streams of type 'Markers', 'EEG' and 'Audio' index can be different\n",
    "assert all([d['info']['type'][0] in data_types for d in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_stream = [d for d in data if d['info']['type'][0] == 'Markers'][0]\n",
    "eeg_stream = [d for d in data if d['info']['type'][0] == 'EEG'][0]\n",
    "# audio_stream = [d for d in data if d['info']['type'][0] == 'Audio'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 \n",
    "stim_file = os.path.join('stimuli','stimuli_words.txt')\n",
    "labels = open(stim_file).read().splitlines()\n",
    "\n",
    "prefix = ['rest', 'stim',  'I', 'S']\n",
    "marker_names = np.array(marker_stream['time_series']).squeeze()\n",
    "marker_dict = {p: i for i, p in enumerate(np.unique(marker_names))}\n",
    "id_binding = {v: k for k, v in marker_dict.items()}\n",
    "category_mapping = {p: [v for k, v in marker_dict.items() if k.startswith(p)] for p in prefix}\n",
    "marker_timestamps = np.array(marker_stream['time_stamps'])\n",
    "modality_timestamps = np.array(eeg_stream['time_stamps'])\n",
    "insert_points = np.searchsorted(modality_timestamps, marker_timestamps)\n",
    "\n",
    "def filter_markers(marker_dict, prefix='stim'):\n",
    "    \"\"\"\n",
    "    Filter markers based on the prefix.\n",
    "    \"\"\"\n",
    "    return {k: v for k, v in marker_dict.items() if k.startswith(prefix)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_labels = ['Fp1', 'Fp2', 'C3', 'C4', 'P7', 'P8', 'O1', 'O2', 'F7', 'F8', 'F3', 'F4', 'T7', 'T8', 'P3', 'P4']\n",
    "sampling_rate = int(eeg_stream['info']['nominal_srate'][0])\n",
    "info = mne.create_info(ch_names=ch_labels, sfreq=sampling_rate, ch_types='eeg')\n",
    "data = eeg_stream[\"time_series\"].T\n",
    "raw = mne.io.RawArray(data, info)\n",
    "raw.set_montage('standard_1020')\n",
    "# raw.drop_channels(['Fp1','P8'])\n",
    "# Apply bandpass filter\n",
    "raw = raw.filter(l_freq=0.3, h_freq=60)\n",
    "# # Apply notch filter\n",
    "raw = raw.notch_filter(freqs=50)\n",
    "\n",
    "label_id_func = np.vectorize(marker_dict.get)\n",
    "events = np.zeros((len(insert_points), 3), dtype=int)\n",
    "events[:, 0] = insert_points\n",
    "events[:, 2] = label_id_func(marker_names)\n",
    "annot = mne.annotations_from_events(events, raw.info['sfreq'], id_binding)\n",
    "raw.set_annotations(annot)\n",
    "\n",
    "# imagine = mne.pick_events(events, include=category_mapping['S'])\n",
    "# epoch = mne.Epochs(raw, imagine, event_id=filter_markers(marker_dict, prefix='S'), tmin=-0.5, tmax=1.5, baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(scalings='auto', events=events, event_id=marker_dict, duration=10, n_channels=16, remove_dc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speak = mne.pick_events(events, include=category_mapping['S'])\n",
    "imagine = mne.pick_events(events, include=category_mapping['I'])\n",
    "# print(speak)\n",
    "s_epochs = mne.Epochs(raw, speak, event_id=filter_markers(marker_dict, prefix='S'), tmin=-0.2, tmax=2, preload=True)\n",
    "i_epochs = mne.Epochs(raw, imagine, event_id=filter_markers(marker_dict, prefix='I'), tmin=-0.2, tmax=2, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_epochs.plot_image(combine='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_epochs.plot_image(combine='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_epochs.compute_psd(fmin=2.0, fmax=40.0).plot(picks=\"data\", exclude=\"bads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_epochs.compute_psd(fmin=2.0, fmax=40.0).plot(picks=\"data\", exclude=\"bads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.logspace(*np.log10([1, 40]), num=8)\n",
    "n_cycles = freqs / 2.0  # different number of cycle per frequency\n",
    "power = mne.time_frequency.tfr_multitaper(s_epochs, freqs=freqs, n_cycles=n_cycles, return_itc=False, average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.plot(\n",
    "    baseline=(None, 0), mode=\"mean\", tmin=-0.5, tmax=2, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = AutoReject()\n",
    "epochs_clean = ar.fit_transform(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_clean.plot(scalings='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_clean.plot_image(combine='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_clean.compute_psd().plot_topomap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked = epochs_clean.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked.plot_joint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = segment_modalities_optimized(marker_stream['time_stamps'], audio_stream['time_stamps'], audio_stream['time_series'].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[6].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'S-Zebra'\n",
    "idx = np.where(marker_names == name)[0][0]\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_audio_data(audio_data_buffer, out_path='audio.wav'):\n",
    "    audio_fs = 44100\n",
    "    sf.write(out_path, audio_data_buffer, audio_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_audio_data(s[idx], f'{name}.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
